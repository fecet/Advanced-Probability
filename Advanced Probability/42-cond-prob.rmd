## Conditional probability and distribution

Recall definition in example \@ref(exm:undergraduate-probability):
$$
\mathop{{}\mathbb{P}}_{\mathcal{F}}H=\mathop{{}\mathbb{E}}_{\mathcal{F}}\bm{1}_{H}=\begin{cases}
    \bm{1}_{H} & H\in \mathcal{F} \\
    \mathop{{}\mathbb{P}}H& H \perp \mathcal{F}
\end{cases}
$$

### Regular versions

Let $Q(A)$ be a version of $\mathop{{}\mathbb{P}}_{\mathcal{F}}A$ for each $A\in \mathcal{A}$. Clearly, $Q(\emptyset)=0$ and $Q(\Omega)=1$. Let $Q(\omega,A)=Q(A)(\omega)=Q_{\omega}(A)$, note

-   $\omega \mapsto Q(\omega,A)=Q(A)(\omega)$ is $\mathcal{F}$ measurable.
-   $A \mapsto Q(\omega,A)=Q_{\omega}(A)$ is a measure:

    1.  Nonnegativity: $Q_{\omega}(A) \ge 0$ for any $A$ clearly and
    1.  $\sigma$-additivity:
        $$
        Q_{\omega}\left( \sum_{n}A_n \right)=\mathop{{}\mathbb{E}}_{\mathcal{F}}\bm{1}_{\sum_{n}A_n}=\mathop{{}\mathbb{E}}_{\mathcal{F}}\sum_{n}^{} \bm{1}_{A_n}=\sum_{n}^{}\mathop{{}\mathbb{E}}_{\mathcal{F}}\bm{1}_{A_n}=\sum_{n}^{}Q_{\omega}(A_n)
        $$

However, the $\sigma$-additivity only enjoyed in a $a.s.$ $\Omega_0$ (as we use the MCT of conditional expectations which works on a $a.s.$ set) and that keeps $Q$ from being a transition kernel. Suppose $\Omega_{a}$ be the $a.s.$ event $w.r.t.$ sequence $a:=(A_n)$. Then we need $\bigcap_{a}\Omega_a$ to be $a.e.$ and this usually be a miserable object as there are uncountable many sequence $a$.

Nevertheless, it's often possible to pick versions of $Q(A)$ $s.t.$ $\bigcap_{a}\Omega_{a}=\Omega$.


::: {.definition  name=""}

$Q(\omega,A)$ is said to be a **regular version** of $\mathop{{}\mathbb{P}}_{\mathcal{F}}$ or a **regular conditional probability** provided that $Q$ is a transition probability kernel from $(\Omega,\mathcal{F})$ into $(\Omega,\mathcal{A})$ and $Q(A)$ is a version of $\mathop{{}\mathbb{P}}_{\mathcal{F}}A$ for any $A\in \mathcal{A}$.

:::

The following is the reason for our interesting in regular version.

::: {.proposition  name=""}

Suppose $\mathop{{}\mathbb{P}}_{\mathcal{F}}$ has a regular version $Q$, then $QX(\omega)=Q_{\omega}X=\int X dQ_{\omega}$ is a version of $\mathop{{}\mathbb{E}}_{\mathcal{F}}X$.

:::


::: {.proof}

WLOG, assume $X\in \mathcal{A}_+$. By theorem \@ref(thm:kernel-op), we have $QX\in \mathcal{F}_+$, then it's sufficient to check the projection property, to see this, suppose $X=\bm{1}_{A}$ for arbitrary $A\in \mathcal{A}$, then for any $V\in \mathcal{F}_{+}$.
$$
\mathop{{}\mathbb{E}}_{}VQX=\mathop{{}\mathbb{E}}_{}VQ \bm{1}_{A}=\mathop{{}\mathbb{E}}_{}VQ(A)=\mathop{{}\mathbb{E}}_{}V \bm{1}_{A}=\mathop{{}\mathbb{E}}_{}VX
$$
then we can extends $X$ to general case and claim follows.

:::

The existence of regular version for $\mathop{{}\mathbb{P}}_{\mathcal{F}}$ require conditions either on $\mathcal{F}$ or $\mathcal{A}$.

-   $\mathcal{F}$ generated by a measurable partition $(\Omega_n)$ of $\Omega$, then
    $$
    Q_{\omega}(A)=\sum_{n}^{} \mathop{{}\mathbb{P}}_{\Omega_n}A \cdot \bm{1}_{\Omega_n}(\omega)=\mathop{{}\mathbb{P}}_{\Omega_i}A
    $$
    where $\Omega_i$ is where $\omega$ located and thus be a measure as so is $\mathop{{}\mathbb{P}}_{\Omega_i}$.
-   When $\mathcal{F}$ is arbitrary, we will use a sequence $(A_n)\subset \mathcal{A}$ and $Q(A_n)$ to form arbitrary $Q(A)$, that require conditions on $\mathcal{A}$ given below.


::: {.theorem  name=""}

If $(\Omega,\mathcal{A})$ is a standard measurable space, then $\mathop{{}\mathbb{P}}_{\mathcal{F}}$ has a regular version.

:::

### Conditional distribution

Let $X \in \mathcal{A}$ be a $r.v.$ taking values in $(E,\mathcal{E})$. Then the **conditional distribution** of $X$ given $\mathcal{F}\subset \mathcal{A}$ is any transition probability kernel $L(\omega,B):(\Omega,\mathcal{F})\to (E,\mathcal{E})$ such that $\forall B\in \mathcal{E}$.
$$
L(\omega,B)=\mathop{{}\mathbb{P}}_{\mathcal{F}}\left\{ X\in B \right\}(\omega)   
$$
If $\mathop{{}\mathbb{P}}_{\mathcal{F}}$ has regular version $Q$, then $Q_{\omega}\left\{ X\in B \right\}$ define a version of $L$. That happen if $(E,\mathcal{E})$ is standard.

### Disintegrations

Recall we can construct $\pi=\mu K$ from probability measure $\mu$ and probability kernel $K$ and then $d \pi= d\mu dK_{x}$, namely,
$$
\pi(dx,dy)=\mu(dx)K(x,dy)
$$
Whence we can regard $\pi$ as joint distribution of $X$ and $Y$, then $K(x,dy)$ is the conditional probability of $dy$ given $X=x$. 

::: {.theorem  name=""}

Let $\pi$ be probability measure on $(D\times E,\mathcal{D}\times \mathcal{E})$, $(E,\mathcal{E})$ is standard, then there exist a probability measure $\mu$ on $(D,\mathcal{D})$ and a probability kernel $K$ $s.t.$ $d\pi=d \mu dK_{x}$.

:::

### Conditional distribution of $Y$ given $X$   


::: {.theorem  name=""}

Suppose the joint distribution $\pi$ of $X,Y \in (\Omega,\mathcal{A})$, taking values in $(D,\mathcal{D})$ and $(E,\mathcal{E})$ respectively, has representation
$$
\pi(dx,dy)=\mu(dx)K(x,dy)
$$
then the kernel $L$ defined by:
$$
L_{\omega}(B)=L(\omega,B)=K(X(\omega),B)
$$
is a version of the conditional distribution of $Y$ given $\mathcal{F}=\sigma X$. And for any $f \in \mathcal{D} \times \mathcal{E}$,
$$
\mathop{{}\mathbb{E}}_{\mathcal{F}}f(X,Y)=\int _{E} K(X,dy)f(X,y)
$$

:::

### Conditional densities









<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
